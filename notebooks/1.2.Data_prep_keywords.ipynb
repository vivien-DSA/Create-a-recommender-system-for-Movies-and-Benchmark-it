{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task to do :\n",
    "\n",
    "**Preprocessed the keywords dataset for the upcoming EDA** :( remove duplicates, handle missing value and mistype columns, remove outliers )\n",
    "\n",
    "The movies dataset -> https://www.kaggle.com/rounakbanik/the-movies-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## First we import all the useful libraries \n",
    ">- Path for filepath managing\n",
    ">- pandas and numpy for dataframe manip \n",
    ">- and for dataviz seaborn and matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">##  We organise our different files directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('../data')\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">##  We load the different datasets into dataframes using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35504</th>\n",
       "      <td>128230</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18000</th>\n",
       "      <td>61730</td>\n",
       "      <td>[{'id': 10183, 'name': 'independent film'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>218</td>\n",
       "      <td>[{'id': 83, 'name': 'saving the world'}, {'id'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                           keywords\n",
       "35504  128230                                                 []\n",
       "18000   61730        [{'id': 10183, 'name': 'independent film'}]\n",
       "1195      218  [{'id': 83, 'name': 'saving the world'}, {'id'..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_keywords_df = pd.read_csv(RAW_DIR / 'keywords.csv')\n",
    "\n",
    "display(raw_keywords_df.sample(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing of the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This dataset contains the movie plot keywords for MovieLens movies. Available in the form of a stringified JSON Object. <br>\n",
    "Columns contents:\n",
    "\n",
    "- **id :** The id of the movie. Movie ids are consistent between `ratings_small.csv`, `movies_metadata.csv`, and `links_small.csv` (i.e., the same id refers to the same movie across these data files).\n",
    "- **keywords:** A stringified dictionary that gives information on the keywords of the film which identifier is the above id.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Information on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46419 entries, 0 to 46418\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        46419 non-null  int64 \n",
      " 1   keywords  46419 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 725.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# basics info\n",
    "raw_keywords_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    45432\n",
       "True       987\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_keywords_df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7055</th>\n",
       "      <td>3022</td>\n",
       "      <td>[{'id': 848, 'name': 'double life'}, {'id': 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26729</th>\n",
       "      <td>47902</td>\n",
       "      <td>[{'id': 10183, 'name': 'independent film'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14219</th>\n",
       "      <td>90056</td>\n",
       "      <td>[{'id': 596, 'name': 'adultery'}, {'id': 9748,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>10394</td>\n",
       "      <td>[{'id': 378, 'name': 'prison'}, {'id': 585, 'n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           keywords\n",
       "7055    3022  [{'id': 848, 'name': 'double life'}, {'id': 15...\n",
       "26729  47902        [{'id': 10183, 'name': 'independent film'}]\n",
       "14219  90056  [{'id': 596, 'name': 'adultery'}, {'id': 9748,...\n",
       "5289   10394  [{'id': 378, 'name': 'prison'}, {'id': 585, 'n..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_keywords_df.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The keywords table has :\n",
    "    >- 46419 rows and 2 columns :\n",
    "    >    - all non-null **( we don't have missing value )**\n",
    "    >    - 987 duplicates rows **(we will drop them)**\n",
    "    >- 1 float and 1 integer \n",
    "    >- keywords have some empty json values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Duplicate rows, Handling missing, incorrect and invalid data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1. Duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the duplicate rows and start to create a processed_keywords_df\n",
    "processed_keywords_df = raw_keywords_df.drop_duplicates().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2. missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3. mistype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'id': 931, 'name': 'jealousy'}, {'id': 4290, 'name': 'toy'}, {'id': 5202, 'name': 'boy'}, {'id': 6054, 'name': 'friendship'}, {'id': 9713, 'name': 'friends'}, {'id': 9823, 'name': 'rivalry'}, {'id': 165503, 'name': 'boy next door'}, {'id': 170722, 'name': 'new toy'}, {'id': 187065, 'name': 'toy comes to life'}]\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us see what is inside \n",
    "processed_keywords_df['keywords'].tolist()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We will use the function extract_name we create to deal with the json\n",
    ">    - extract_name is in handle_json file in package_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the function\n",
    "import sys\n",
    "sys.path.append('../package_folder')\n",
    "\n",
    "from handle_json import extract_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the name of the cast and saving it\n",
    "processed_keywords_df.keywords = processed_keywords_df.keywords.apply(extract_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24911</th>\n",
       "      <td>183111</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29897</th>\n",
       "      <td>118612</td>\n",
       "      <td>coma|crash|accepting death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23757</th>\n",
       "      <td>242095</td>\n",
       "      <td>hacker|supernatural powers|road trip|independe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                           keywords\n",
       "24911  183111                                                NaN\n",
       "29897  118612                         coma|crash|accepting death\n",
       "23757  242095  hacker|supernatural powers|road trip|independe..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_keywords_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# They is no other way to deal with empty value than deleting because with don't have other informations\n",
    "processed_keywords_df = processed_keywords_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we explode the keywords\n",
    "# processed_keywords_df.keywords = processed_keywords_df.keywords.str.split('|')\n",
    "# processed_keywords_df = processed_keywords_df.explode('keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For convenience we will rename id column to movieId\n",
    "processed_keywords_df = processed_keywords_df.rename(columns={\"id\": \"movieId\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We won't explode it now but later on EDA if needed will do it\n",
    "# We will stop here and save our preprocess data\n",
    "processed_keywords_df.to_csv(PROCESSED_DIR/ 'keywords.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
